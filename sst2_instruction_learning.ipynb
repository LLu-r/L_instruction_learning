{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SST-2 Instruction Learning 多模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境配置与数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ssl\n",
    "import urllib3\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 SST-2 数据集\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "val_dataset = dataset[\"validation\"]\n",
    "print(f\"验证集样本数: {len(val_dataset)}\")\n",
    "print(val_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "prompt_style = \"\"\"Below is an instruction that describes a task, paired with\n",
    "an input that provides further context. Write a response that appropriately\n",
    "completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Analyze the given text from an online review and determine the sentiment\n",
    "polarity. Return a single number of either 0 and 1, with 0 being negative\n",
    "and 1 being the positive sentiment.\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "def extract_prediction(text):\n",
    "    \"\"\"从模型输出中提取预测结果 (0 或 1)\"\"\"\n",
    "    if \"### Response:\" in text:\n",
    "        after_response = text.split(\"### Response:\")[-1]\n",
    "    else:\n",
    "        after_response = text\n",
    "    \n",
    "    matches = re.findall(r'\\b([01])\\b', after_response)\n",
    "    if matches:\n",
    "        return int(matches[0])\n",
    "    \n",
    "    text_lower = after_response.lower()\n",
    "    if \"negative\" in text_lower:\n",
    "        return 0\n",
    "    elif \"positive\" in text_lower:\n",
    "        return 1\n",
    "    \n",
    "    return -1\n",
    "\n",
    "def evaluate_model(model_id, model_name):\n",
    "    \"\"\"评估模型并返回准确率\"\"\"\n",
    "    print(f\"加载模型: {model_id}\")\n",
    "    \n",
    "    pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        max_new_tokens=64,\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    pipeline.tokenizer.pad_token_id = pipeline.tokenizer.eos_token_id\n",
    "    pipeline.tokenizer.padding_side = \"left\"\n",
    "    \n",
    "    predictions = []\n",
    "    idx_list = list(val_dataset['idx'])\n",
    "    true_labels = list(val_dataset['label'])\n",
    "    prompts = [prompt_style.format(item['sentence']) for item in val_dataset]\n",
    "    \n",
    "    print(f\"开始评估，共 {len(prompts)} 个样本...\")\n",
    "\n",
    "    for i in range(0, len(prompts), BATCH_SIZE):\n",
    "        batch_prompts = prompts[i:i+BATCH_SIZE]\n",
    "        responses = pipeline(batch_prompts)\n",
    "        \n",
    "        for response in responses:\n",
    "            output_text = response[0][\"generated_text\"]\n",
    "            pred_label = extract_prediction(output_text)\n",
    "            predictions.append(pred_label)\n",
    "        \n",
    "        if (i + BATCH_SIZE) % 200 == 0 or i + BATCH_SIZE >= len(prompts):\n",
    "            current_acc = accuracy_score(true_labels[:len(predictions)], predictions)\n",
    "            print(f\"进度: {len(predictions)}/{len(val_dataset)}，当前准确率: {current_acc:.4f}\")\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    \n",
    "    # 保存预测结果\n",
    "    result_output = pd.DataFrame(data={\"idx\": idx_list, \"prediction\": predictions})\n",
    "    csv_name = f\"sst2_{model_name}.csv\"\n",
    "    result_output.to_csv(csv_name, index=False, quoting=3)\n",
    "    print(f\"预测结果已保存到 {csv_name}\")\n",
    "    \n",
    "    # 清理显存\n",
    "    del pipeline\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n最终准确率: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    return accuracy\n",
    "\n",
    "# 存储所有结果\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Qwen 系列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen2.5-0.5B\n",
    "acc = evaluate_model(\"Qwen/Qwen2.5-0.5B-Instruct\", \"Qwen2.5-0.5B\")\n",
    "all_results[\"Qwen2.5-0.5B\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen2.5-1.5B\n",
    "acc = evaluate_model(\"Qwen/Qwen2.5-1.5B-Instruct\", \"Qwen2.5-1.5B\")\n",
    "all_results[\"Qwen2.5-1.5B\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen2.5-3B\n",
    "acc = evaluate_model(\"Qwen/Qwen2.5-3B-Instruct\", \"Qwen2.5-3B\")\n",
    "all_results[\"Qwen2.5-3B\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen2.5-7B\n",
    "acc = evaluate_model(\"Qwen/Qwen2.5-7B-Instruct\", \"Qwen2.5-7B\")\n",
    "all_results[\"Qwen2.5-7B\"] = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Llama 系列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama-3.2-1B\n",
    "acc = evaluate_model(\"meta-llama/Llama-3.2-1B-Instruct\", \"Llama-3.2-1B\")\n",
    "all_results[\"Llama-3.2-1B\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama-3.2-3B\n",
    "acc = evaluate_model(\"meta-llama/Llama-3.2-3B-Instruct\", \"Llama-3.2-3B\")\n",
    "all_results[\"Llama-3.2-3B\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama-3.1-8B\n",
    "acc = evaluate_model(\"meta-llama/Llama-3.1-8B-Instruct\", \"Llama-3.1-8B\")\n",
    "all_results[\"Llama-3.1-8B\"] = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gemma 系列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemma-2-2B\n",
    "acc = evaluate_model(\"google/gemma-2-2b-it\", \"Gemma-2-2B\")\n",
    "all_results[\"Gemma-2-2B\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemma-2-9B\n",
    "acc = evaluate_model(\"google/gemma-2-9b-it\", \"Gemma-2-9B\")\n",
    "all_results[\"Gemma-2-9B\"] = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Phi-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phi-4\n",
    "acc = evaluate_model(\"microsoft/phi-4\", \"Phi-4\")\n",
    "all_results[\"Phi-4\"] = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mistral 系列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mistral-7B\n",
    "acc = evaluate_model(\"mistralai/Mistral-7B-Instruct-v0.3\", \"Mistral-7B\")\n",
    "all_results[\"Mistral-7B\"] = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 结果汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印所有结果\n",
    "print(\"=\" * 50)\n",
    "print(\"SST-2 Instruction Learning Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Model':<25} {'Accuracy':<15}\")\n",
    "print(\"-\" * 40)\n",
    "for name, acc in sorted(all_results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name:<25} {acc:.4f} ({acc*100:.2f}%)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 保存汇总\n",
    "summary_df = pd.DataFrame([\n",
    "    {\"model\": name, \"accuracy\": acc} for name, acc in all_results.items()\n",
    "]).sort_values(\"accuracy\", ascending=False)\n",
    "summary_df.to_csv(\"sst2_instruction_learning_summary.csv\", index=False)\n",
    "print(\"\\n汇总已保存到 sst2_instruction_learning_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
